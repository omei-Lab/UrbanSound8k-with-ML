{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0143882",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae694884",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = pickle.load(open('../data/label_dict.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8118d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_10fold(model, name, data_dir='../data/orig'):\n",
    "    accuracies = []\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for test_id in range(10):\n",
    "        dfs = []\n",
    "        for i in range(10):\n",
    "            if i != test_id:\n",
    "                df = pd.read_csv(f'{data_dir}/fold{i}.csv')\n",
    "                dfs.append(df)\n",
    "        train_df = pd.concat(dfs, ignore_index=True)\n",
    "        test_df = pd.read_csv(f'{data_dir}/fold{test_id}.csv')\n",
    "\n",
    "        # X, y\n",
    "        X_train, y_train = train_df.drop(['label', 'audio'], axis=1), train_df['label']\n",
    "        X_test, y_test = test_df.drop(['label', 'audio'], axis=1), test_df['label']\n",
    "\n",
    "        # train & evaluation\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(acc)\n",
    "\n",
    "        all_preds.extend(y_pred)\n",
    "        all_labels.extend(y_test)\n",
    "\n",
    "        print(f'Fold {test_id} Accuracy: {acc:.4f}')\n",
    "\n",
    "    print(f'\\nAverage Accuracy: {np.mean(accuracies):.4f}')\n",
    "    print(f'Total: {len(all_labels)}')\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'Confusion Matrix (10-Fold CV) Using {name}')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n",
    "    \n",
    "    print(classification_report(all_labels, all_preds))\n",
    "\n",
    "    return all_preds, all_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe19fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(verbose=0)\n",
    "_ = train_with_10fold(lr, 'Logistic')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105ea16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "_ = train_with_10fold(knn, 'KNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9957fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(kernel='rbf')\n",
    "_ = train_with_10fold(svc, 'SVM (RBF kernel)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e17bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "_ = train_with_10fold(rf, 'Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f897e22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgb = LGBMClassifier(verbose = 0)\n",
    "_ = train_with_10fold(lgb, 'LightGBM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914e09bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "_ = train_with_10fold(xgb, 'XGBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "54b9bcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_before_tuning = {\n",
    "    'Logistic': {'0': 0.36, '1': 0.57, '2': 0.54, '3': 0.59, '4': 0.60, \n",
    "                 '5': 0.52, '6': 0.67, '7': 0.57, '8': 0.69, '9': 0.58},\n",
    "    'KNN':      {'0': 0.35, '1': 0.55, '2': 0.45, '3': 0.56, '4': 0.48, \n",
    "                 '5': 0.48, '6': 0.76, '7': 0.39, '8': 0.64, '9': 0.56},\n",
    "    'SVM-RBF':  {'0': 0.38, '1': 0.66, '2': 0.56, '3': 0.66, '4': 0.64, \n",
    "                 '5': 0.57, '6': 0.81, '7': 0.54, '8': 0.71, '9': 0.64},\n",
    "    'RF':       {'0': 0.38, '1': 0.59, '2': 0.53, '3': 0.62, '4': 0.57, \n",
    "                 '5': 0.56, '6': 0.77, '7': 0.59, '8': 0.71, '9': 0.60},\n",
    "    'LGBM':     {'0': 0.34, '1': 0.60, '2': 0.55, '3': 0.63, '4': 0.58, \n",
    "                 '5': 0.53, '6': 0.78, '7': 0.58, '8': 0.71, '9': 0.62},\n",
    "    'XGB':      {'0': 0.35, '1': 0.59, '2': 0.54, '3': 0.63, '4': 0.58, \n",
    "                 '5': 0.52, '6': 0.79, '7': 0.55, '8': 0.70, '9': 0.63},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1598b9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results_before_tuning).T  # 模型為 index，label 為 column\n",
    "df = df.reset_index().melt(id_vars='index', var_name='Class', value_name='F1-score')\n",
    "df.rename(columns={'index': 'Model'}, inplace=True)\n",
    "\n",
    "# 對照 label 名稱（如果有 label_dict 的話）\n",
    "df['Class'] = df['Class'].astype(int).map(label_dict)\n",
    "\n",
    "# 繪圖\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.barplot(data=df, x='Class', y='F1-score', hue='Model')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Per-class F1-score comparison across models\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "654d26e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_before_tuning = {\n",
    "    \"Logistic\": 0.5595,\n",
    "    \"KNN\": 0.4962,\n",
    "    \"SVM-RBF\": 0.6029,\n",
    "    \"RF\": 0.5857,\n",
    "    \"LGBM\": 0.5847,\n",
    "    \"XGB\": 0.5813\n",
    "}\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'model': acc_before_tuning.keys(),\n",
    "    'acc': acc_before_tuning.values()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1274e0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 7)) \n",
    "ax = sns.barplot(data=df, x='model', y='acc', palette = 'deep')\n",
    "\n",
    "for i in range(6):\n",
    "\tax.bar_label(ax.containers[i], fmt='%.4f', fontsize=12) \n",
    "\n",
    "plt.title(\"Overall Model Accuracy Comparison\", fontsize=16, pad=20)\n",
    "plt.xlabel(\"Model\", fontsize=14)\n",
    "plt.xticks(fontsize=12) \n",
    "plt.ylabel(\"Accuracy\", fontsize=14) \n",
    "sns.despine()\n",
    "plt.tight_layout() \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
